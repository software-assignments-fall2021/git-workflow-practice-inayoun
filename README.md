# Git Practice

**Article:** [Machine learning and bias](https://developer.ibm.com/articles/machine-learning-and-bias/?mhsrc=ibmsearch_a&mhq=%20)

Machine learning is growingly becoming a more prevalent technology in various industries. The article talks about examples biases in machine learning used for chatting bots and job applicant screenings. We know that the bias is caused by the data, but the article delves into more detail on representative data, and how bias in data will translate into bias in the algorithm. 

I found IBM's AI Fairness 360 interesting to read about. AI Fairness 360 is a toolkit that includes many fairness metrics and bias mitigation algorithms that detect and remove bias. Because the inner workings of machine learning algorithms are often not entirely clear, pinpointing the exact cause of the bias may be a challenge developers will need to overcome.

#### Comment
It is crazy to me that strong gender/race biases are so prevalent in AI/ML systems. It seems as though more representative data sets should really be used more.
